---
layout: post
title: '不用程式寫爬蟲記錄(Kimono Desktop)'
date: 2016-11-27 05:25
comments: true
categories: 實用工具
tags: [爬蟲,Kimono]
---
前幾天看到[無痛爬梳自己來，用 Google Spreadsheet 爬取網頁資料](http://blog.infographics.tw/2016/11/google-spreadsheet-data-scraping/)
就想之前的Kimono
但現在官網要收掉這個服務
不過有官網友留下kimono desktop edition 離線版程式使用(只有MAC和Windows)
目前不知道有沒有辦法移植到Linux上面玩

|                              | kimonolabs.com           | kimono for desktop
------------------------------|---------------------------|----------------------
Create APIs with Chrome Ext		|v                          |
Create APIs with Bookmarklet	|	v                         |v
Manage and configure APIs		  |v                          |v
Run APIs manually		          |v                          |
Run APIs on a schedule        |v                          |
Cloud hosted API endpoints    |		                        |v (w/ Firebase)
Crawling & Pagination		      |v                          |v
Get data behind a login	      |	v                         |v
Kimono Apps / Blocks		      |v                          |
Google sheets integration     |v
Webhooks & Email alerts		    |v
Save scraped data to file	    |	v                        |v
CSV & RSS output		          |v                         | v

當然離線版沒有這麼多功能，可惜沒有排程可以用
但發現他程式透過NodeJS去寫，好像可以透過API方式去實作
在此先記錄一下筆記


<!--more-->


首先，安裝kimono desktop edition 和chrome extension
相關套件網路就一堆，我就先偷懶拉o.<
[不會寫程式也能爬，Kimono 幫你把網站變資料](http://blog.infographics.tw/2015/04/crawl-data-without-code-using-kimonolabs/)

API建立好，開kimono desktop edition可以看到剛剛家加入的任務
![k1.png](http://user-image.logdown.io/user/8284/blog/8171/post/1147900/4xl8wny7RwWp7WYxUY9l_k1.png)


![k2.png](http://user-image.logdown.io/user/8284/blog/8171/post/1147900/hJk274dUQWevRRnnZ50e_k2.png)


![k3.png](http://user-image.logdown.io/user/8284/blog/8171/post/1147900/yIHnKB00Ta6ZkdISSZ7V_k3.png)
按下Start Crawl 可執行爬蟲

後來我發現kimono desktop edition可以開啟開發者工具
發現執行Web API可以跑爬蟲
看來排程執行爬蟲指日可待XD

![k4.png](http://user-image.logdown.io/user/8284/blog/8171/post/1147900/0oIV98RT9K5ZIULkibM3_k4.png)
```
POST /ws/startcrawl/ HTTP/1.1
Host: localhost:3000
Origin: http://localhost:3000
X-DevTools-Emulate-Network-Conditions-Client-Id: 93A1E1D6-2642-4DD4-84B2-5BAE0E75261C
User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) kimono-desktop/1.0.5 Chrome/45.0.2454.85 Electron/0.35.4 Safari/537.36
Content-Type: application/json;charset=UTF-8
Referer: http://localhost:3000/apis/b8ed4oy2
Accept-Encoding: gzip, deflate
Accept-Language: zh-TW
Cache-Control: no-cache
Postman-Token: 0b770020-6467-cff2-5923-6300dc330def

{"apiid":"b8ed4oy2"}
```

![k5.png](http://user-image.logdown.io/user/8284/blog/8171/post/1147900/lHJfAnWyQ2C8wbHncI7t_k5.png)

看爬蟲API任務的狀態WEB API
